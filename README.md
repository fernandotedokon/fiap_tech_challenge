# ğŸ“š Biblioteca de livros

Esta API implementada em Python com FastAPI extrai informaÃ§Ãµes de livros do site [Books to Scrape](https://books.toscrape.com/), armazena os dados no arquivo "books.csv" e fornece rotas para consulta.


## ğŸ“¦ Requisitos

- Python 3.8+
- pip


## ğŸ—‚ï¸ Estrutura do Projeto

```
biblioteca/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ scraper.py         # Scraper de livros e utilitÃ¡rios de unificaÃ§Ã£o
â”‚   â”œâ”€â”€ models.py          # Modelos ML serializados
â”‚   â””â”€â”€ utils.py           # FunÃ§Ãµes auxiliares auxiliam na consulta das informaÃ§Ãµes
â”œâ”€â”€ data/
â”‚   â””â”€â”€ books.csv          # CSVs exportados e unificados
â”œâ”€â”€ main.py                # Inicializador do pipeline e da API
â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto com as bibliotecas utilizada
â””â”€â”€ README.md
```



## âš™ï¸ Como Executar o Projeto

### 1. Clone o repositÃ³rio

```bash
git clone <https://github.com/fernandotedokon/fiap-tech-challenge.git>
cd fiap-tech-challenge
```

### 2. Crie e ative um ambiente virtual

```bash
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Inicie o FlastAPI

```bash
uvicorn main:app --reload
```

### 5. Swagger - Verificar todas as rotas criadas funcionalidades disponiveis

No swagger vocÃª poderÃ¡ verificar e executar todas as rotas criadas.
```bash
http://127.0.0.1:8000/docs
```

### 6. Execute o Web Scraping executando a rota (opcional, se jÃ¡ houver CSV)

```bash
/api/v1/extrair/{pages}

Esse mÃ©todo extrai e salva livros de acordo com o nÃºmero de pÃ¡ginas informado. VocÃª pode solicitar entre 1 a 10 pÃ¡ginas ou exatamente 50 pÃ¡ginas para extrair todos os dados. Ele chama uma funÃ§Ã£o que faz a extraÃ§Ã£o, carrega os livros e retorna a quantidade de livros extraÃ­dos.
```
Isso irÃ¡ baixar os dados dos livros e gerar os arquivos CSV em `data/books.csv`.


---


## ğŸ“¡ Principais Endpoints Core

| MÃ©todo | Rota                                    | DescriÃ§Ã£o |
|--------|-----------------------------------------|-----------|
| GET    | /api/v1/extrair/{pages}                 | Extrai e salva livros de acordo nÃºmero de pÃ¡ginas informado |
| GET    | /api/v1/health                          | Verifica status da API |
| GET    | /api/v1/books                           | Lista todos os livros |
| GET    | /api/v1/books/{id}                      | Detalha um livro |
| GET    | /api/v1/books/search?title=&category=   | Busca por tÃ­tulo/categoria |
| GET    | /api/v1/categories                      | Lista categorias Ãºnicas |


## ğŸ“¡ Endpoints de Insights

| MÃ©todo | Rota                                    | DescriÃ§Ã£o |
|--------|-----------------------------------------|-----------|
| GET    | /api/v1/stats/overview                  | EstatÃ­sticas gerais da coleÃ§Ã£o (total de livros, preÃ§o mÃ©dio, distribuiÃ§Ã£o de ratings) |
| GET    | /api/v1/stats/categories                | EstatÃ­sticas detalhadas por categoria (quantidade de livros, preÃ§os por categoria) |
| GET    | /api/v1/books/top-rated                | Lista os livros com melhor avaliaÃ§Ã£o
(rating mais alto) |
| GET    | /api/v1/books/price-range                | Filtra livros dentro de uma faixa de preÃ§o especÃ­fica |




## ğŸ§  scraper.py: ExtraÃ§Ã£o dos livros
- Realiza a extraÃ§Ã£o de dados (web scraping) do site "https://books.toscrape.com/". Coleta informaÃ§Ãµes sobre os livros disponÃ­veis na pÃ¡gina, como tÃ­tulo, preÃ§o, disponibilidade, avaliaÃ§Ã£o, categoria, URL da imagem e detalhes especÃ­ficos de cada livro. Verifica uma ou mais pÃ¡ginas do site (dependendo do parÃ¢metro pages), extrai os dados de cada livro listado, acessa a pÃ¡gina de detalhes de cada um para obter informaÃ§Ãµes adicionais, e entÃ£o salva tudo em um arquivo CSV chamado "books.csv". Faz a coleta e organizaÃ§Ã£o das informaÃ§Ãµes de livros de forma automatizada.


## ğŸ“¦ models.py Modelos da API
- Modelo com a definiÃ§Ã£o dos campos, atributos do livro que serÃ£o extraidos do site [Books to Scrape](https://books.toscrape.com/).


## ğŸ›  utils.py: FunÃ§Ãµes auxiliares
- Os mÃ©todos do arquivo utils.py sÃ£o funÃ§Ãµes auxiliares que ajudam a manipular e consultar uma base de dados de livros armazenada em um arquivo CSV.



#### 1. load_books(): 
- Carrega todos os livros do arquivo CSV e retorna um DataFrame do pandas com esses dados.

#### 2. get_book_by_id(book_id): 
- Busca um livro especÃ­fico pelo seu ID. Se encontrar, retorna um dicionÃ¡rio com as informaÃ§Ãµes desse livro; se nÃ£o, retorna None.

#### 3. search_books(title=None, category=None): 
- Permite procurar livros pelo tÃ­tulo ou pela categoria. VocÃª pode usar um ou ambos os filtros. Ele retorna uma lista de dicionÃ¡rios com os livros que correspondem aos critÃ©rios.

#### 4. get_categories(): 
- Lista todas as categorias de livros disponÃ­veis, sem repetiÃ§Ãµes, em ordem alfabÃ©tica.

#### 5. get_stats_overview(): 
- Mostra o resumo do tamanho da coleÃ§Ã£o, quanto, em mÃ©dia, eles custam e como as avaliaÃ§Ãµes estÃ£o distribuÃ­das.

#### 6. get_stats_by_category(): 
- Fornece uma visÃ£o geral das categorias de livros, incluindo quantos livros hÃ¡ em cada uma e os preÃ§os mÃ©dios, mÃ¡ximos e mÃ­nimos.

#### 7. get_top_rated_books(): 
- Verifica a avaliaÃ§Ã£o mais alta entre os livros e seleciona aqueles que receberam essa nota mÃ¡xima.





## ğŸš€ main.py: Rotas da API
- Os mÃ©todos do arquivo main.py sÃ£o responsÃ¡veis por criar e gerenciar a API da sua biblioteca.

---
ğŸ“ Extrair Dados
#### /api/v1/extrair/{pages}
- Esse mÃ©todo extrai e salva livros de acordo com o nÃºmero de pÃ¡ginas informado. VocÃª pode solicitar entre 1 a 10 pÃ¡ginas ou exatamente 50 pÃ¡ginas para extrair todos os dados. Ele chama uma funÃ§Ã£o que faz a extraÃ§Ã£o, carrega os livros e retorna a quantidade de livros extraÃ­dos.

---
âœ… Health Check
#### /api/v1/health
- Essa rota verifica se a API estÃ¡ funcionando bem. Ela tenta carregar os livros e retorna um status "ok" junto com a quantidade de livros disponÃ­veis. Ã‰ como um teste de saÃºde do sistema.

---
ğŸ“š Listar Todos os Livros
#### /api/v/books
- Aqui vocÃª consegue listar todos os livros disponÃ­veis na sua biblioteca. Ela retorna uma lista com os detalhes de cada livro.

---
ğŸ” Buscar Livro por ID
#### /api/v1/books/{id}
- Essa rota busca um livro especÃ­fico pelo seu ID. Se encontrar, retorna os detalhes do livro; se nÃ£o, informa que o livro nÃ£o foi encontrado.

---
ğŸ” Buscar por TÃ­tulo e/ou Categoria
#### /api/v1/books/search
- Essa busca permite procurar livros pelo tÃ­tulo ou pela categoria. VocÃª pode passar um ou ambos os parÃ¢metros para filtrar os resultados.

---
ğŸ“‚ Listar Categorias
#### /api/v1/categories
- Essa rota retorna todas as categorias de livros disponÃ­veis na sua biblioteca.

---
ğŸ“Š VisÃ£o geral sobre uma coleÃ§Ã£o de livros
#### /api/v1/stats/overview
- Ã‰ uma maneira bem prÃ¡tica de obter uma visÃ£o rÃ¡pida e resumida sobre os livros que estÃ£o no sistema

---
ğŸ“Š Fornece estatÃ­sticas por categoria
#### /api/v1/stats/categories
- Muito Ãºtil para dashboards ou anÃ¡lises por Ã¡rea temÃ¡tica, retorna a quantidade de livros, preÃ§o mÃ©dio, mÃ¡ximo e mÃ­nimo por categoria.

---
ğŸ“Š Fornece todos os livros com avaliaÃ§Ã£o mÃ¡xima
#### /api/v1/books/top-rated
- Mostra os melhores livros da base.

---
ğŸ“Š Buscar livros que estÃ£o dentro de uma faixa de preÃ§o especÃ­fica
#### /api/v1/books/price-range
- VocÃª pode informar um valor mÃ­nimo e um valor mÃ¡ximo, e ela vai retornar uma lista de livros cujo preÃ§o estÃ¡ entre esses dois valores.




---
## ğŸ§­ Plano Arquitetural (Pipeline e Escalabilidade)

### ğŸ”„ Pipeline da SoluÃ§Ã£o

```
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ books.toscrape.com
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
             â”‚  (requests + BS4)
             â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Scraper Python â”‚
      â”‚ scraper.py     â”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼  (CSV: pandas)
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  data/books.csv    â”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   FastAPI backend  â”‚
      â”‚   main.py + models â”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  REST Endpoints    â”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Cientistas de Dados  â”‚
     â”‚   Frontends / ML / BI  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


## ğŸ§± Arquitetura Pensada para Escalabilidade Futura

| Componente      | EscalÃ¡vel? | EstratÃ©gia                                                |
| --------------- | ---------- | --------------------------------------------------------- |
| Scraper         | âœ…          | Tornar assÃ­ncrono, paralelizar scraping por pÃ¡ginas       |
| Armazenamento   | âš ï¸ CSV     | Migrar para PostgreSQL, MongoDB, ou S3                    |
| API FastAPI     | âœ…          | Pode escalar horizontalmente com Gunicorn/Uvicorn         |
| Modelo de Dados | âœ…          | Pydantic permite validaÃ§Ã£o forte                          |
| Deploy          | âœ…          | Docker, Kubernetes, serverless (AWS Lambda + API Gateway) |



## ğŸ§  Caso de Uso para Cientistas de Dados / ML

### ğŸ¯ CenÃ¡rio
Objetivo: Cientistas de dados querem explorar livros para entender preferÃªncias por categorias, preÃ§os, disponibilidade e aplicar tÃ©cnicas de NLP.

ğŸ’¼ AplicaÃ§Ãµes:
ğŸ” AnÃ¡lise exploratÃ³ria de dados (EDA)

ğŸ“Š Dashboard com Streamlit, Dash ou Power BI

ğŸ¤– Treinamento de modelos de recomendaÃ§Ã£o ou classificaÃ§Ã£o de livros por categoria

ğŸ§  AnÃ¡lise de sentimento via scraping de reviews (futuro)



## ğŸ§  IntegraÃ§Ã£o com Modelos de Machine Learning

### ğŸ§© Plano de IntegraÃ§Ã£o
| Etapa             | Detalhes                                                                       |
| ----------------- | ------------------------------------------------------------------------------ |
| Dados             | `books.csv` como entrada para prÃ©-processamento                                |
| PrÃ©-processamento | Limpeza, encoding de `rating`, one-hot de `category`, transformaÃ§Ã£o de `price` |
| Treinamento       | Classificadores, clusterizaÃ§Ã£o de livros, sistemas de recomendaÃ§Ã£o             |
| API ML            | Servir modelo via FastAPI ou usar ferramenta como BentoML ou TorchServe        |
| IntegraÃ§Ã£o        | Nova rota `/api/v1/predict` que recebe dados de entrada e retorna previsÃ£o     |


## ğŸ”„ Exemplo de Rota Futuro:

```bash
@app.post("/api/v1/predict")
def predict(data: Book):
    # Preprocessar dados
    # Carregar modelo treinado
    # Retornar resultado
    return {"categoria_prevista": "Fiction"}
```


## ğŸ“ˆ SugestÃ£o para Pipeline de ML

```bash
data/books.csv â”€â”€> Jupyter Notebook â”€â”€> Modelo treinado (.pkl/.joblib)
                                           â”‚
FastAPI â”€â”€ /predict â”€â”€â”€â”€â”€â”€â”€â”€> Carrega modelo e retorna inferÃªncia
```